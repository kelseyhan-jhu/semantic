{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import torch\n",
    "import numpy as np\n",
    "from utils import word2sense, regression, listdir, image_to_tensor, Subject, cv_regression\n",
    "from train import mean_condition_features\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge\n",
    "import scipy.stats as stats\n",
    "from collections import OrderedDict \n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from feature_extractors import AlexNetConv5\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load visual features\n",
    "alexnet = torch.load('features_conv5.pth') # dict with 1470 * 12544 features\n",
    "\n",
    "alexnet_reshape = copy.deepcopy(alexnet)\n",
    "for item in alexnet_reshape:\n",
    "    alexnet_reshape[item] = np.reshape(alexnet_reshape[item], (256, 7, 7))\n",
    "                             \n",
    "vgg = torch.load('features_vgg16_conv5.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load semantic embeddings\n",
    "with open('ThingsWrd2Sns.txt', 'r', encoding='utf-8') as txt:\n",
    "    temp = txt.readlines()\n",
    "nDim = 2250\n",
    "wordlist = [line.split(',')[0] for idx, line in enumerate(temp) if idx != 0] # create word list\n",
    "word2sense = {new_list: np.zeros((1, nDim)) for new_list in wordlist} # create (word: embedding) dictionary\n",
    "for i, line in enumerate(temp):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    embedding = line.split(',')\n",
    "    embedding.remove('\\n')\n",
    "    embedding_float = ([float(j) for j in embedding[1:]])\n",
    "   \n",
    "    word2sense[embedding[0]] = np.array(embedding_float)\n",
    "word2sense = OrderedDict(word2sense)\n",
    "\n",
    "embeddings = word2sense\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wordvec filtered by CM\n",
    "wordvec = {}\n",
    "with open('ThingsWrd2Vec_subset.txt', 'r', encoding='utf-8') as txt:\n",
    "    temp = txt.readlines()\n",
    "\n",
    "for i, wv in enumerate(temp):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    w = (temp[i].split(','))[0]\n",
    "    if w in word2sense:\n",
    "        wordvec[w] = temp[i].split(',')[1:]\n",
    "        wordvec[w][-1] = wordvec[w][-1].replace('\\n', '')\n",
    "\n",
    "for wv in wordvec:\n",
    "    wordvec[wv] = np.array(wordvec[wv]).astype(np.float)\n",
    "\n",
    "embeddings = wordvec\n",
    "features = {item: alexnet[item] for item in alexnet.keys() if item in wordvec}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([item for item in alexnet.keys() if item in wordvec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "featsize = vgg['/home/chan21/projects/semanticdimensionality/kh/object2vec_encoder_python/images/aardvark'].shape[0]\n",
    "nfeat = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-a. Let's cross-validate visual -> semantic regression, with unit removal\n",
    "\n",
    "acc = []\n",
    "kf = KFold(n_splits = 9)\n",
    "\n",
    "\n",
    "for i in range(256):\n",
    "    alexnet_temp = copy.deepcopy(alexnet_reshape)\n",
    "    for item in alexnet_temp:\n",
    "        alexnet_temp[item][i][:][:] = 0\n",
    "    rs = []\n",
    "    pred = []\n",
    "    test = []\n",
    "    for train_index, test_index in kf.split(np.stack([np.reshape(feature, (featsize,)) for feature in alexnet_temp.values()])):\n",
    "        train_regressor = np.stack([np.reshape(feature, (featsize,)) for i, feature in enumerate(alexnet_temp.values()) if i in train_index])\n",
    "        test_regressor = np.stack([np.reshape(feature, (featsize,)) for i, feature in enumerate(alexnet_temp.values()) if i in test_index])\n",
    "        train_predictor = np.stack([embedding for i, embedding in enumerate(embeddings.values()) if i in train_index])\n",
    "        test_predictor = np.stack([embedding for i, embedding in enumerate(embeddings.values()) if i in test_index])\n",
    "        regr = Ridge(alpha=0, fit_intercept=False)\n",
    "        regr.fit(train_regressor, train_predictor)\n",
    "        pred_predictor = regr.predict(test_regressor) \n",
    "        pred.append(pred_predictor)\n",
    "        test.append(test_predictor) \n",
    "    preds = np.vstack([p for p in pred])\n",
    "    tests = np.vstack([t for t in test])\n",
    "\n",
    "    for dim in range(preds.shape[1]): \n",
    "        r, _ = stats.pearsonr(preds[:, dim], tests[:, dim]) # compute voxelwise Pearson correlation \n",
    "        rs.append(r)   \n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.bar(range(0, 2250), rs)\n",
    "    mean_r = np.nanmean(np.array(rs), axis=0)\n",
    "    print(mean_r)\n",
    "    #acc.append(mean_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-b. Now, let's cv visual -> Object2vec, fMRI with unit removal.\n",
    "subjects = [1, 2, 3, 4]\n",
    "rois = ['LOC']\n",
    "for roi in rois:\n",
    "    sub_voxel_regressor = {}\n",
    "    for subj in subjects:\n",
    "        subject = Subject(subj, [roi])\n",
    "        voxel_regressor = np.stack([condition_voxel for condition, condition_voxel in (subject.condition_voxels).items()])\n",
    "        sub_voxel_regressor[subj] = voxel_regressor\n",
    "\n",
    "        #print(sub_voxel_regressor[subj].shape)\n",
    "    all_voxel_regressor = np.hstack([sub_voxel_regressor[s] for s in subjects])\n",
    "\n",
    "acc = []\n",
    "kf = KFold(n_splits = 9)\n",
    "\n",
    "feat_extractor = AlexNetConv5()\n",
    "c_feat = mean_condition_features(feat_extractor, nfeat)\n",
    "\n",
    "c_feat_reshape = copy.deepcopy(c_feat)\n",
    "for item in c_feat_reshape:\n",
    "    c_feat_reshape[item] = np.reshape(c_feat_reshape[item], (nfeat, 11, 11))\n",
    "\n",
    "for i in range(mfeat):\n",
    "    c_feat_temp = copy.deepcopy(c_feat_reshape)\n",
    "    for item in c_feat_temp:\n",
    "        c_feat_temp[item][i][:][:] = 0\n",
    "    rs = []\n",
    "    pred = []\n",
    "    test = []\n",
    "    for train_index, test_index in kf.split(np.stack([np.reshape(feature, (12544,)) for feature in c_feat_temp.values()])):\n",
    "        train_regressor = np.stack([np.reshape(feature, (12544,)) for i, feature in enumerate(c_feat_temp.values()) if i in train_index])\n",
    "        test_regressor = np.stack([np.reshape(feature, (12544,)) for i, feature in enumerate(c_feat_temp.values()) if i in test_index])\n",
    "        train_predictor = all_voxel_regressor[train_index, :]\n",
    "        test_predictor = all_voxel_regressor[test_index, :]\n",
    "        regr = Ridge(alpha=0, fit_intercept=False)\n",
    "        regr.fit(train_regressor, train_predictor)\n",
    "        pred_predictor = regr.predict(test_regressor) \n",
    "        pred.append(pred_predictor)\n",
    "        test.append(test_predictor) \n",
    "    preds = np.vstack([p for p in pred])\n",
    "    tests = np.vstack([t for t in test])\n",
    "\n",
    "    for dim in range(preds.shape[1]): \n",
    "        r, _ = stats.pearsonr(preds[:, dim], tests[:, dim]) # compute voxelwise Pearson correlation \n",
    "        rs.append(r)   \n",
    "\n",
    "    mean_r = np.nanmean(np.array(rs), axis=0)\n",
    "    print(mean_r)\n",
    "    acc.append(mean_r)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc[255], acc[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv regression with Things fMRI\n",
    "subjects = ['subj001/', 'subj002/', 'subj003/', 'subj004/']\n",
    "rois = ['LOC']\n",
    "layers = ['conv5']\n",
    "predictpath = {\n",
    "    \"alexnetreal\": \"predictedww/\",\n",
    "    \"alexnetrandom\": \"predicted1026weight2/\",\n",
    "    \"vggreal\": \"predictedvgg/\",\n",
    "}\n",
    "weight = \"alexnetreal\"\n",
    "for roi in rois:\n",
    "    for layer in layers:\n",
    "        sub_voxel_regressor = {}\n",
    "        for subj in subjects:\n",
    "            path = predictpath[weight]\n",
    "            fmri_path = path + subj + roi + \"_\" + layer\n",
    "            fmri_path = os.path.join(os.getcwd(), fmri_path) \n",
    "\n",
    "            conditions = sorted(listdir(fmri_path))\n",
    "            condition_voxels = {}\n",
    "            for condition in conditions:\n",
    "                if condition.split('/')[-1] in alexnet.keys():\n",
    "                    file_name = listdir((os.path.join(fmri_path, condition)))[0]\n",
    "                    file_path = os.path.join(fmri_path, condition, file_name)\n",
    "                    condition_voxels[condition] = np.load(file_path) \n",
    "            voxel_regressor = np.stack([condition_voxel for condition, condition_voxel in OrderedDict(condition_voxels).items()])\n",
    "            sub_voxel_regressor[subj] = voxel_regressor\n",
    "\n",
    "            #print(sub_voxel_regressor[subj].shape)\n",
    "        all_voxel_regressor = np.hstack([sub_voxel_regressor[s] for s in subjects])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load rank by vis->sem\n",
    "acc = np.load('./UnitRemoval/r_vis2sem.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save (load) alexnet features for object2vec\n",
    "feat_extractor = AlexNetConv5()\n",
    "c_feat = mean_condition_features(feat_extractor, 256)\n",
    "\n",
    "c_feat_reshape = copy.deepcopy(c_feat)\n",
    "for item in c_feat_reshape:\n",
    "    c_feat_reshape[item] = np.reshape(c_feat_reshape[item], (256, 7, 7))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv regression with Object2vec fMRI\n",
    "subjects = [1, 2, 3, 4]\n",
    "rois = ['LOC']\n",
    "for roi in rois:\n",
    "    sub_voxel_regressor = {}\n",
    "    for subj in subjects:\n",
    "        subject = Subject(subj, [roi])\n",
    "        voxel_regressor = np.stack([condition_voxel for condition, condition_voxel in (subject.condition_voxels).items()])\n",
    "        sub_voxel_regressor[subj] = voxel_regressor\n",
    "\n",
    "        #print(sub_voxel_regressor[subj].shape)\n",
    "    all_voxel_regressor = np.hstack([sub_voxel_regressor[s] for s in subjects])\n",
    "\n",
    "rs = []\n",
    "pred = []\n",
    "test = []\n",
    "kf = KFold(n_splits = 9)\n",
    "for train_index, test_index in kf.split(np.stack([np.reshape(feature, (12544,)) for feature in c_feat.values()])):\n",
    "    train_regressor = np.stack([np.reshape(feature, (12544,)) for i, feature in enumerate(c_feat.values()) if i in train_index])\n",
    "    test_regressor = np.stack([np.reshape(feature, (12544,)) for i, feature in enumerate(c_feat.values()) if i in test_index])\n",
    "    train_predictor = all_voxel_regressor[train_index, :]\n",
    "    test_predictor = all_voxel_regressor[test_index, :]\n",
    "    regr = Ridge(alpha=0, fit_intercept=False)\n",
    "    regr.fit(train_regressor, train_predictor)\n",
    "    pred_predictor = regr.predict(test_regressor) \n",
    "    pred.append(pred_predictor)\n",
    "    test.append(test_predictor) \n",
    "preds = np.vstack([p for p in pred])\n",
    "tests = np.vstack([t for t in test])\n",
    "for dim in range(preds.shape[1]): \n",
    "    r, _ = stats.pearsonr(preds[:, dim], tests[:, dim]) # compute voxelwise Pearson correlation \n",
    "    rs.append(r)   \n",
    "\n",
    "mean_r_baseline = np.nanmean(np.array(rs), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(0, 256, 257)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the unit removal effects based on semantic richness on: \n",
    "# 1-a-i. fMRI encoding - Object2vec\n",
    "\n",
    "acc_fmri = []\n",
    "for i in range(0, 256, 1):\n",
    "    alexnet_temp = copy.deepcopy(alexnet_reshape)\n",
    "    maxidx = np.argsort(np.array(acc))[:i]\n",
    "    maxidx = (np.linspace(0, 256, 257))[:i]\n",
    "    if i == 0:\n",
    "        acc_fmri.append(mean_r_baseline)\n",
    "    else:\n",
    "        for n in maxidx:\n",
    "            for item in c_feat_temp:\n",
    "                c_feat_temp[item][n][:][:] = 0\n",
    "    rs = []\n",
    "    pred = []\n",
    "    test = []\n",
    "    for train_index, test_index in kf.split(np.stack([np.reshape(feature, (12544,)) for feature in alexnet_temp.values()])):\n",
    "        train_regressor = np.stack([np.reshape(feature, (12544,)) for i, feature in enumerate(alexnet_temp.values()) if i in train_index])\n",
    "        test_regressor = np.stack([np.reshape(feature, (12544,)) for i, feature in enumerate(alexnet_temp.values()) if i in test_index])\n",
    "        train_predictor = all_voxel_regressor[train_index, :]\n",
    "        test_predictor = all_voxel_regressor[test_index, :]\n",
    "        regr = Ridge(alpha=0, fit_intercept=False)\n",
    "        regr.fit(train_regressor, train_predictor)\n",
    "        pred_predictor = regr.predict(test_regressor) \n",
    "        pred.append(pred_predictor)\n",
    "        test.append(test_predictor) \n",
    "    preds = np.vstack([p for p in pred])\n",
    "    tests = np.vstack([t for t in test])\n",
    "\n",
    "    for dim in range(preds.shape[1]): \n",
    "        r, _ = stats.pearsonr(preds[:, dim], tests[:, dim]) # compute voxelwise Pearson correlation \n",
    "        rs.append(r)   \n",
    "    \n",
    "    mean_r = np.nanmean(np.array(rs), axis=0)\n",
    "    acc_fmri.append(mean_r)\n",
    "    \n",
    "# x = np.linspace(0, 257, 257)\n",
    "# title_font = {'fontname':'DejaVu Sans', 'size':'15', 'color':'black', 'weight':'normal',\n",
    "#       'verticalalignment':'bottom'} # Bottom vertical alignment for more space\n",
    "# axis_font = {'fontname':'DejaVu Sans', 'size':'10'}\n",
    "# sns.set()\n",
    "# plt.figure(figsize=(10,5))\n",
    "# plt.xlabel('Number of visual features removed (ranked by predictability on semantic embeddings)', **axis_font)\n",
    "# plt.ylabel('Prediction accuracy on fMRI response (Object2vec)', **axis_font)\n",
    "# plt.title(\"Linear regression: x (AlexNet Conv5 visual features), y (fMRI response)\", **title_font)\n",
    "# plt.plot(x, np.array(acc_fmri))\n",
    "# sns.reset_defaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the unit removal effects based on semantic richness on: \n",
    "# 1-a-i. fMRI encoding - Object2vec (sequential)\n",
    "feat_extractor = AlexNetConv5()\n",
    "c_feat = mean_condition_features(feat_extractor, 256)\n",
    "\n",
    "c_feat_reshape = copy.deepcopy(c_feat)\n",
    "for item in c_feat_reshape:\n",
    "    c_feat_reshape[item] = np.reshape(c_feat_reshape[item], (256, 7, 7))\n",
    "\n",
    "acc_fmri_seq = []\n",
    "for u in range(0, 256, 1):\n",
    "    c_feat_temp = copy.deepcopy(c_feat_reshape)\n",
    "    maxidx = np.arange(0, 256, 1)[:u]\n",
    "    for n in maxidx:\n",
    "        for item in c_feat_temp:\n",
    "            c_feat_temp[item][n][:][:] = 0\n",
    "    rs = []\n",
    "    pred = []\n",
    "    test = []\n",
    "    for train_index, test_index in kf.split(np.stack([np.reshape(feature, (12544,)) for feature in c_feat_temp.values()])):\n",
    "        train_regressor = np.stack([np.reshape(feature, (12544,)) for i, feature in enumerate(c_feat_temp.values()) if i in train_index])\n",
    "        test_regressor = np.stack([np.reshape(feature, (12544,)) for i, feature in enumerate(c_feat_temp.values()) if i in test_index])\n",
    "        train_predictor = all_voxel_regressor[train_index, :]\n",
    "        test_predictor = all_voxel_regressor[test_index, :]\n",
    "        regr = Ridge(alpha=0, fit_intercept=False)\n",
    "        regr.fit(train_regressor, train_predictor)\n",
    "        pred_predictor = regr.predict(test_regressor) \n",
    "        pred.append(pred_predictor)\n",
    "        test.append(test_predictor) \n",
    "    preds = np.vstack([p for p in pred])\n",
    "    tests = np.vstack([t for t in test])\n",
    "\n",
    "    for dim in range(preds.shape[1]): \n",
    "        r, _ = stats.pearsonr(preds[:, dim], tests[:, dim]) # compute voxelwise Pearson correlation \n",
    "        rs.append(r)   \n",
    "    \n",
    "    mean_r = np.nanmean(np.array(rs), axis=0)\n",
    "    acc_fmri_seq.append(mean_r)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Let's see the unit removal effects based on semantic richness on: \n",
    "# 1-a-i. fMRI encoding - Object2vec (random)\n",
    "feat_extractor = AlexNetConv5()\n",
    "c_feat = mean_condition_features(feat_extractor, 256)\n",
    "\n",
    "c_feat_reshape = copy.deepcopy(c_feat)\n",
    "for item in c_feat_reshape:\n",
    "    c_feat_reshape[item] = np.reshape(c_feat_reshape[item], (256, 7, 7))\n",
    "\n",
    "acc_fmri_random = []\n",
    "\n",
    "l = random.sample(list(np.arange(0, 256, 1)), 256)\n",
    "for u in range(0, 256, 1):\n",
    "    c_feat_temp = copy.deepcopy(c_feat_reshape)\n",
    "    \n",
    "    maxidx = l[:u]\n",
    "    print(maxidx)\n",
    "    for n in maxidx:\n",
    "        for item in c_feat_temp:\n",
    "            c_feat_temp[item][n][:][:] = 0\n",
    "    rs = []\n",
    "    pred = []\n",
    "    test = []\n",
    "    for train_index, test_index in kf.split(np.stack([np.reshape(feature, (12544,)) for feature in c_feat_temp.values()])):\n",
    "        train_regressor = np.stack([np.reshape(feature, (12544,)) for i, feature in enumerate(c_feat_temp.values()) if i in train_index])\n",
    "        test_regressor = np.stack([np.reshape(feature, (12544,)) for i, feature in enumerate(c_feat_temp.values()) if i in test_index])\n",
    "        train_predictor = all_voxel_regressor[train_index, :]\n",
    "        test_predictor = all_voxel_regressor[test_index, :]\n",
    "        regr = Ridge(alpha=0, fit_intercept=False)\n",
    "        regr.fit(train_regressor, train_predictor)\n",
    "        pred_predictor = regr.predict(test_regressor) \n",
    "        pred.append(pred_predictor)\n",
    "        test.append(test_predictor) \n",
    "    preds = np.vstack([p for p in pred])\n",
    "    tests = np.vstack([t for t in test])\n",
    "\n",
    "    for dim in range(preds.shape[1]): \n",
    "        r, _ = stats.pearsonr(preds[:, dim], tests[:, dim]) # compute voxelwise Pearson correlation \n",
    "        rs.append(r)   \n",
    "    \n",
    "    mean_r = np.nanmean(np.array(rs), axis=0)\n",
    "    acc_fmri_random.append(mean_r)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_fmri = np.load(\"UnitRemoval/r_vis2sem_1fmri.npy\")\n",
    "x = np.linspace(0, 257, 257)\n",
    "title_font = {'fontname':'DejaVu Sans', 'size':'15', 'color':'black', 'weight':'normal',\n",
    "      'verticalalignment':'bottom'} # Bottom vertical alignment for more space\n",
    "axis_font = {'fontname':'DejaVu Sans', 'size':'10'}\n",
    "sns.set()\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.xlabel('Number of visual features removed (ranked by predictability on semantic embeddings)', **axis_font)\n",
    "plt.ylabel('Prediction accuracy on fMRI response (Object2vec)', **axis_font)\n",
    "plt.title(\"Linear regression: x (AlexNet Conv5 visual features), y (fMRI response)\", **title_font)\n",
    "plt.plot(x, np.array(acc_fmri), color='red', label='ablation by prediction accuracy')\n",
    "x = np.linspace(0, 257, 256)\n",
    "\n",
    "plt.plot(x, np.array(acc_fmri_seq), color='blue', label='sequential ablation')\n",
    "plt.plot(x, np.array(acc_fmri_random), color='green', label='random ablation')\n",
    "\n",
    "plt.legend(prop={'size': 14});\n",
    "\n",
    "sns.reset_defaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.argsort(np.array(acc))[:255])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the unit removal effects based on fMRI prediction on: \n",
    "# 1-b-i. semantic embedding\n",
    "\n",
    "acc_ = []\n",
    "for u in range(0, 256, 1):\n",
    "    alexnet_temp = copy.deepcopy(alexnet)\n",
    "    maxidx = np.argsort(np.array(acc))[:u]\n",
    "    for n in maxidx:\n",
    "        for item in alexnet_temp:\n",
    "            alexnet_temp[item][n][:][:] = 0\n",
    "    rs = []\n",
    "    pred = []\n",
    "    test = []\n",
    "    for train_index, test_index in kf.split(np.stack([np.reshape(feature, (12544,)) for feature in alexnet_temp.values()])):\n",
    "        train_regressor = np.stack([np.reshape(feature, (12544,)) for i, feature in enumerate(alexnet_temp.values()) if i in train_index])\n",
    "        test_regressor = np.stack([np.reshape(feature, (12544,)) for i, feature in enumerate(alexnet_temp.values()) if i in test_index])\n",
    "        train_predictor = np.stack([embedding for i, embedding in enumerate(word2sense.values()) if i in train_index])\n",
    "        test_predictor = np.stack([embedding for i, embedding in enumerate(word2sense.values()) if i in test_index])\n",
    "        regr = Ridge(alpha=0, fit_intercept=False)\n",
    "        regr.fit(train_regressor, train_predictor)\n",
    "        pred_predictor = regr.predict(test_regressor) \n",
    "        pred.append(pred_predictor)\n",
    "        test.append(test_predictor) \n",
    "    preds = np.vstack([p for p in pred])\n",
    "    tests = np.vstack([t for t in test])\n",
    "\n",
    "    for dim in range(preds.shape[1]):\n",
    "        r, _ = stats.pearsonr(preds[:, dim], tests[:, dim]) # compute voxelwise Pearson correlation \n",
    "        rs.append(r)   \n",
    "    \n",
    "    mean_r = np.nanmean(np.array(rs), axis=0)\n",
    "    acc_.append(mean_r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the unit removal effects based on fMRI prediction on: \n",
    "# 1-b-i. semantic embedding (sequential, random)\n",
    "\n",
    "acc_random = []\n",
    "\n",
    "l = random.sample(list(np.arange(0, 256, 1)), 256)\n",
    "    \n",
    "for u in range(0, 256, 1):\n",
    "    alexnet_temp = copy.deepcopy(alexnet)\n",
    "    #maxidx = np.argsort(np.array(acc))[:u]\n",
    "    #maxidx = np.arange(0, 256, 1)[:u]\n",
    "    maxidx = l[:u]\n",
    "\n",
    "    for n in maxidx:\n",
    "        for item in alexnet_temp:\n",
    "            alexnet_temp[item][n][:][:] = 0\n",
    "    rs = []\n",
    "    pred = []\n",
    "    test = []\n",
    "    for train_index, test_index in kf.split(np.stack([np.reshape(feature, (12544,)) for feature in alexnet_temp.values()])):\n",
    "        train_regressor = np.stack([np.reshape(feature, (12544,)) for i, feature in enumerate(alexnet_temp.values()) if i in train_index])\n",
    "        test_regressor = np.stack([np.reshape(feature, (12544,)) for i, feature in enumerate(alexnet_temp.values()) if i in test_index])\n",
    "        train_predictor = np.stack([embedding for i, embedding in enumerate(word2sense.values()) if i in train_index])\n",
    "        test_predictor = np.stack([embedding for i, embedding in enumerate(word2sense.values()) if i in test_index])\n",
    "        regr = Ridge(alpha=0, fit_intercept=False)\n",
    "        regr.fit(train_regressor, train_predictor)\n",
    "        pred_predictor = regr.predict(test_regressor) \n",
    "        pred.append(pred_predictor)\n",
    "        test.append(test_predictor) \n",
    "    preds = np.vstack([p for p in pred])\n",
    "    tests = np.vstack([t for t in test])\n",
    "\n",
    "    for dim in range(preds.shape[1]):\n",
    "        r, _ = stats.pearsonr(preds[:, dim], tests[:, dim]) # compute voxelwise Pearson correlation \n",
    "        rs.append(r)   \n",
    "    \n",
    "    mean_r = np.nanmean(np.array(rs), axis=0)\n",
    "    #acc_seq.append(mean_r)\n",
    "    acc_random.append(mean_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"UnitRemoval/r_vis2fmri_1sem\", acc_)\n",
    "x = np.linspace(0, 256, 256)\n",
    "title_font = {'fontname':'DejaVu Sans', 'size':'15', 'color':'black', 'weight':'normal',\n",
    "      'verticalalignment':'bottom'} # Bottom vertical alignment for more space\n",
    "axis_font = {'fontname':'DejaVu Sans', 'size':'10'}\n",
    "sns.set()\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.xlabel('Number of visual features removed (ranked by predictability on fMRI response)', **axis_font)\n",
    "plt.ylabel('Prediction accuracy on semantic embeddings (Things)', **axis_font)\n",
    "plt.title(\"Linear regression: x (AlexNet Conv5 visual features), y (Word2sense)\", **title_font)\n",
    "plt.plot(x, np.array(acc_), color='red', label='ablation by prediction accuracy')\n",
    "plt.plot(x, np.array(acc_seq), color='blue', label='sequential ablation')\n",
    "plt.plot(x, np.array(acc_random), color='green', label='random ablation')\n",
    "\n",
    "plt.legend(prop={'size': 14});\n",
    "\n",
    "sns.reset_defaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) classification - Things category prediction with linear classifier\n",
    "\n",
    "\n",
    "for i in range(1, 256, 1):\n",
    "    alexnet_temp = copy.deepcopy(alexnet_reshape)\n",
    "    maxidx = np.argsort(np.array(acc))[:i]\n",
    "    for n in maxidx:\n",
    "        for item in alexnet_temp:\n",
    "            alexnet_temp[item][n][:][:] = 0\n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstEnv",
   "language": "python",
   "name": "firstenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
